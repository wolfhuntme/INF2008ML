import os
import numpy as np
import pandas as pd
import joblib
import cv2
from skimage.feature import hog
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# =============================
# 1. Load and Process Bank Transactions Data
# =============================
file_path = "bank_transactions_data.csv"  # Update this with actual path
df = pd.read_csv(file_path)

df['TransactionDate'] = pd.to_datetime(df['TransactionDate'])
df['PreviousTransactionDate'] = pd.to_datetime(df['PreviousTransactionDate'])
df['TransactionHour'] = df['TransactionDate'].dt.hour
df['TransactionDay'] = df['TransactionDate'].dt.day
df['TransactionMonth'] = df['TransactionDate'].dt.month
df['TimeSinceLastTransaction'] = (df['TransactionDate'] - df['PreviousTransactionDate']).dt.total_seconds()

categorical_cols = ['TransactionType', 'Location', 'DeviceID', 'MerchantID', 'Channel', 'CustomerOccupation']
label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

feature_cols = [
    'TransactionAmount', 'TransactionHour', 'TransactionDay', 'TransactionMonth',
    'TimeSinceLastTransaction', 'TransactionType', 'Location', 'DeviceID',
    'MerchantID', 'Channel', 'CustomerAge', 'CustomerOccupation', 'TransactionDuration',
    'LoginAttempts', 'AccountBalance'
]

np.random.seed(42)
df['FraudLabel'] = np.random.choice([0, 1], size=len(df), p=[0.95, 0.05])

X = df[feature_cols]
y = df['FraudLabel']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_scaled, y_train)

joblib.dump(rf_model, "fraud_detection_model.pkl")
joblib.dump(scaler, "scaler.pkl")

print(f"Transaction Fraud Model Accuracy: {accuracy_score(y_test, rf_model.predict(X_test_scaled)):.2f}")

# =============================
# 2. Load and Process Signature Images
# =============================
IMG_SIZE = (150, 150)
genuine_path = "signatures_cedar/small_org"  # Path for genuine signatures
forged_path = "signatures_cedar/small_forg"  # Path for forged signatures

def load_images(folder, label):
    images, labels = [], []
    for filename in os.listdir(folder):
        file_path = os.path.join(folder, filename)
        if os.path.isfile(file_path):
            img = load_img(file_path, target_size=IMG_SIZE)
            img = img_to_array(img) / 255.0  # Normalize
            images.append(img)
            labels.append(label)
    return np.array(images), np.array(labels)

genuine_images, genuine_labels = load_images(genuine_path, label=1)
forged_images, forged_labels = load_images(forged_path, label=0)

X_signatures = np.concatenate([genuine_images, forged_images])
y_signatures = np.concatenate([genuine_labels, forged_labels])

X_train_sig, X_test_sig, y_train_sig, y_test_sig = train_test_split(X_signatures, y_signatures, test_size=0.2, random_state=42)

# =============================
# 3. Train Signature Verification Model (HOG + SVM)
# =============================
def extract_hog(image):
    gray = cv2.cvtColor((image * 255).astype('uint8'), cv2.COLOR_RGB2GRAY)
    return hog(gray, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm='L2-Hys')

X_train_hog = np.array([extract_hog(img) for img in X_train_sig])
X_test_hog = np.array([extract_hog(img) for img in X_test_sig])

svm_model = SVC(kernel='linear', probability=True, random_state=42)
svm_model.fit(X_train_hog, y_train_sig)
joblib.dump(svm_model, "svm_signature_model.pkl")

print(f"Signature Verification Model Accuracy: {accuracy_score(y_test_sig, svm_model.predict(X_test_hog)):.2f}")

# =============================
# 4. Load and Test Fraud Detection Model
# =============================
rf_model = joblib.load("fraud_detection_model.pkl")
scaler = joblib.load("scaler.pkl")
svm_model = joblib.load("svm_signature_model.pkl")

def predict_fraud(transaction_features, signature_pair, weight_transaction=0.7, weight_signature=0.3):
    print("Testing with transaction features:", transaction_features)
    transaction_features_scaled = scaler.transform(pd.DataFrame([transaction_features], columns=feature_cols))
    transaction_fraud_prob = rf_model.predict_proba(transaction_features_scaled)[0][1]
    
    feat1, feat2 = extract_hog(signature_pair[0]), extract_hog(signature_pair[1])
    diff = np.abs(feat1 - feat2).reshape(1, -1)
    signature_fraud_prob = svm_model.predict_proba(diff)[0][1]
    
    final_fraud_score = (weight_transaction * transaction_fraud_prob) + (weight_signature * signature_fraud_prob)
    final_label = 1 if final_fraud_score > 0.5 else 0
    
    return final_label, final_fraud_score

# Test multiple transactions
for i in range(5):  # Test on 5 random transactions
    sample_transaction = X_test.iloc[i].values
    test_signature_pair = [X_test_sig[i], X_test_sig[i+1]]  # Use consecutive images

    fraud_label, fraud_score = predict_fraud(sample_transaction, test_signature_pair)
    actual_label = y_test.iloc[i]

    print(f"Test {i+1}:")
    print(f"Predicted Fraud Label: {'Fraudulent' if fraud_label else 'Legitimate'}")
    print(f"Actual Fraud Label: {'Fraudulent' if actual_label == 1 else 'Legitimate'}")
    print(f"Fraud Score: {fraud_score:.2f}")
    print("=" * 40)
