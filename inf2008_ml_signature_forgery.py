# -*- coding: utf-8 -*-
"""INF2008 ML SIGNATURE FORGERY

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y63E2q0IDfRWt45qzPsfCyZ3-9WMfYmG
"""

import os
import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.layers import Lambda
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

"""MOUNT DATASET"""

# from google.colab import drive
# drive.mount('/content/drive')

"""LOAD IN DATASET"""

# Define paths
genuine_path = r'C:\Users\Vyse\Documents\GitHub\Machine-Learning\Dataset_Signature_Final\Dataset\dataset1\real'
forged_path = r'C:\Users\Vyse\Documents\GitHub\Machine-Learning\Dataset_Signature_Final\Dataset\dataset1\forge'

# Function to parse filenames
def parse_filename(filename):
    person_id = int(filename[:3])  # XXX
    sample_num = int(filename[3:5])  # YY
    signature_id = int(filename[5:8])  # ZZZ
    return person_id, sample_num, signature_id

# Load images and labels
def load_images(folder):
    images = []
    labels = []
    for filename in os.listdir(folder):
        img = load_img(os.path.join(folder, filename), target_size=(150, 150))
        img = img_to_array(img) / 255.0  # Normalize
        images.append(img)
        person_id, _, signature_id = parse_filename(filename)
        labels.append(1 if person_id == signature_id else 0)  # 1 for genuine, 0 for forged
    return np.array(images), np.array(labels)

# Load genuine and forged images
genuine_images, genuine_labels = load_images(genuine_path)
forged_images, forged_labels = load_images(forged_path)

# Combine datasets
X = np.concatenate([genuine_images, forged_images])
y = np.concatenate([genuine_labels, forged_labels])

"""Create Positive and Negative Pairs"""

def create_pairs(images, labels):
    pairs = []
    pair_labels = []
    num_classes = len(np.unique(labels))

    # Create positive pairs (same class)
    for i in range(len(images)):
        for j in range(i + 1, len(images)):
            if labels[i] == labels[j]:
                pairs.append([images[i], images[j]])
                pair_labels.append(1)  # 1 for positive pair

    # Create negative pairs (different classes)
    for i in range(len(images)):
        for j in range(i + 1, len(images)):
            if labels[i] != labels[j]:
                pairs.append([images[i], images[j]])
                pair_labels.append(0)  # 0 for negative pair

    return np.array(pairs), np.array(pair_labels)

# Create pairs
pairs, pair_labels = create_pairs(X, y)

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(pairs, pair_labels, test_size=0.2, random_state=42)

"""TRAINING MODEL"""

def build_siamese_network(input_shape):
    input = Input(shape=input_shape)
    x = layers.Conv2D(32, (3, 3), activation='relu')(input)
    x = layers.MaxPooling2D((2, 2))(x)
    x = layers.Conv2D(64, (3, 3), activation='relu')(x)
    x = layers.MaxPooling2D((2, 2))(x)
    x = layers.Flatten()(x)
    x = layers.Dense(128, activation='relu')(x)
    return Model(input, x)

# Define inputs and subnetworks
input_shape = (150, 150, 3)
input_a = Input(shape=input_shape)
input_b = Input(shape=input_shape)
siamese_network = build_siamese_network(input_shape)
output_a = siamese_network(input_a)
output_b = siamese_network(input_b)

# Compute Euclidean distance between outputs
distance = Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([output_a, output_b])
prediction = layers.Dense(1, activation='sigmoid')(distance)

# Compile the model
model = Model(inputs=[input_a, input_b], outputs=prediction)
model.compile(optimizer=Adam(0.0001), loss=BinaryCrossentropy(), metrics=['accuracy'])
model.summary()

# Split training pairs into inputs
train_a = X_train[:, 0]
train_b = X_train[:, 1]

# Train the model
history = model.fit(
    [train_a, train_b], y_train,
    validation_data=([X_test[:, 0], X_test[:, 1]], y_test),
    epochs=15,
    batch_size=32
)

# Plot training history
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Evaluate on test data
test_loss, test_acc = model.evaluate([X_test[:, 0], X_test[:, 1]], y_test)
print(f"Test Accuracy: {test_acc * 100:.2f}%")

model.save('siamese_signature_model.h5')

# Load the model for inference
loaded_model = tf.keras.models.load_model('siamese_signature_model.h5')

# Predict on a new pair
def predict_pair(image1_path, image2_path):
    img1 = load_img(image1_path, target_size=(150, 150))
    img1 = img_to_array(img1) / 255.0
    img2 = load_img(image2_path, target_size=(150, 150))
    img2 = img_to_array(img2) / 255.0
    prediction = loaded_model.predict([np.array([img1]), np.array([img2])])
    return "Genuine" if prediction > 0.5 else "Forged"

# Example usage
# print(predict_pair('path_to_genuine_image.png', 'path_to_test_image.png'))